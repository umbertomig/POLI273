{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# POLI 273\n",
    "\n",
    "## Causal Inference\n",
    "\n",
    "### Lecture 06 - DAGs for Causal Identification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Announcements\n",
    "\n",
    "- This class GitHub: https://github.com/umbertomig/POLI273\n",
    "\n",
    "- PS01: How is it going?\n",
    "\n",
    "- Qualtrics Videos: It is still missing the Conjoint Video and the Case-Control Video.\n",
    "    + I'll post them this week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda for Today\n",
    "\n",
    "- DAGs:\n",
    "    + d-Separation\n",
    "    + Backdoor criterion\n",
    "    + Why they are good / connections with PO.\n",
    "    \n",
    "- Regression Analysis:\n",
    "    + Linear Regression\n",
    "    + Consistency\n",
    "    + Regression for Causal Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "- Three relations in the paths:\n",
    "    + Chains: \n",
    "    \n",
    "    $$T \\longrightarrow C \\longrightarrow Y$$\n",
    "    \n",
    "    + Forks: \n",
    "    \n",
    "    $$T \\longleftarrow C \\longrightarrow Y$$\n",
    "    \n",
    "    + Inverted Forks (Colliders): \n",
    "    \n",
    "    $$T \\longrightarrow C \\longleftarrow Y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "- Consider this DAG (Elwert, 2013):\n",
    "\n",
    "![img](../img/dag1.png)\n",
    "\n",
    "- Let us see what happens in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "- [Pearl 1988] **d-Separation**: A path between two variables $A$ and $B$ is said to be d-separated (blocked; closed) if:\n",
    "    1. The path contains a **non-collider that has been conditioned on**, OR\n",
    "    2. The path contains a **collider that has *not* been conditioned on**.\n",
    "\n",
    "\n",
    "- [Verma and Pearl, 1988]:\n",
    "    1. If two variables $A$ and $B$ are d-separated, then $A \\perp B$.\n",
    "    2. If two variables $A$ and $B$ are d-separated conditional on a third variable (or sets of variables) $C$, then $A \\perp B | C$.\n",
    "    3. If your DAG is faithful and the variables $A$ and $B$ are d-connected (or not d-separated), then they are dependent (faithfulness: assumes your DAG is certain; weak faithfulness: assume your DAG is a conjecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "- Are $X$ and $Y$ d-separated?\n",
    "\n",
    "![img](../img/dag3.png)\n",
    "\n",
    "1. Draw the paths.\n",
    "2. Study them.\n",
    "3. What happens when you start conditioning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "- [Shpister et al. 2010]: **Adjustment criterion**: A set of observed variables $Z$ (that may be empty) satisfies the adjustment criterion relative to the total causal effect of a treatment $T$ on an outcome $Y$ if:\n",
    "    1. $Z$ blocks all non-causal paths from $Z$ to $Y$, AND\n",
    "    2. No variable in $Z$ lies on or decents from a causal path from $T$ to $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "Consider the following DAG, where we are interested in the effect of a treatment $T$ on $Y$:\n",
    "\n",
    "![img](../img/dag6.png)\n",
    "\n",
    "1. Draw the paths.\n",
    "2. Study them.\n",
    "3. Can we use the adjustment criterion to identify the effects causally? (Hint: Nine possible adjustments. Find two)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "- [Definition]: **Backdoor Path**: Non-causal paths that start with an arrow into the treatment. ($ \\longrightarrow T$)\n",
    "\n",
    "- [Pearl 1993]: **Backdoor criterion**: A set of observed variables $Z$ (that may be empty) satisfies the backdoor criterion relative to the total causal effect of a treatment $T$ on an outcome $Y$ if:\n",
    "    1. No element of $Z$ is a descendant of $T$, AND\n",
    "    2. $Z$ blocks all backdoor paths from $T$ to $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "Consider the following DAG, where we are interested in the effect of a treatment $T$ on $Y$:\n",
    "\n",
    "![img](../img/dag7.png)\n",
    "\n",
    "1. Draw the paths.\n",
    "2. Study them.\n",
    "3. Can we use the *backdoor criterion* to identify the effect causally? (Met by seven adjustments. Find two.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## DAGs\n",
    "\n",
    "- More on DAGs later. Now, let us see the implication for Experimental Political Science.\n",
    "\n",
    "- Suppose we have a random treatment $Z$ and an outcome of interest $Y$. And let us assume that:\n",
    "\n",
    "$$ (Y_{1}, Y_{0}) \\perp Z \\ \\text{ and positivity}$$\n",
    "\n",
    "This means that: \n",
    "\n",
    "- $Y_1 \\perp Z$ and $Y_0 \\perp Z$. From what we know from the adjustment criterion: \n",
    "\n",
    "$$ \\tau = \\mathbb{E}\\big[Y_{1} - Y_{0}\\big] =  \\mathbb{E}\\big[Y_{1}\\big] -  \\mathbb{E}\\big[Y_{0}\\big] $$\n",
    "\n",
    "![img](../img/dag4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DAGs\n",
    "\n",
    "- Suppose we have a treatment $Z$, a variable $X$, and an outcome of interest $Y$. And let us assume that:\n",
    "\n",
    "$$ (Y_{1}, Y_{0}) \\perp Z | X \\ \\text{ and positivity}$$\n",
    "\n",
    "- This means that:\n",
    "\n",
    "1. $\\mathbb{E}\\big[Y_1\\big] = \\sum_{\\text{Supp}(X)} \\mathbb{E}[Y|Z = 1, X = x]\\mathbb{P}(X = x)$ \n",
    "2. $\\mathbb{E}\\big[Y_0\\big] = \\sum_{\\text{Supp}(X)} \\mathbb{E}[Y|Z = 0, X = x]\\mathbb{P}(X = x)$ \n",
    "\n",
    "And:\n",
    "\n",
    "$$ \\tau = \\mathbb{E}\\big[Y_{1} - Y_{0}\\big] =  \\mathbb{E}\\big[Y_{1}\\big] -  \\mathbb{E}\\big[Y_{0}\\big] $$\n",
    "\n",
    "![img](../img/dag5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression for Causal Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "- A linear regression is a *special* projection on a space.\n",
    "\n",
    "- Suppose we have two sets of variables $(X, y)$ ($X$ can be more than one var).\n",
    "\n",
    "- The conditional expectation of $y$ given $X$ can be decompose as:\n",
    "\n",
    "$$ \\bf{y} = \\mathbb{E}\\big[\\bf{y} \\ | \\ \\bf{X}\\big] + \\bf{\\varepsilon} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "$$ \\bf{y} = \\mathbb{E}\\big[\\bf{y} \\ | \\ \\bf{X}\\big] + \\bf{\\varepsilon} $$\n",
    "\n",
    "And if this is the case, then:\n",
    "\n",
    "**Theorem:** $\\mathbb{E}\\big[\\bf{\\varepsilon} \\ | \\ \\bf{X} \\big] = \\bf{0}$. Moreover:\n",
    "\n",
    "1. For any function $\\phi$, $\\mathbb{E}\\big[\\phi(\\bf{X})\\bf{\\varepsilon} \\big] = \\bf{0}$.\n",
    "\n",
    "2. In particular: $\\mathbb{E}\\big[\\bf{X}'\\bf{\\varepsilon} \\big] = \\bf{0} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "- Now, pick the result: \n",
    "\n",
    "$$\\mathbb{E}(\\bf{X}'\\varepsilon) = 0$$\n",
    "\n",
    "- What does it mean? \n",
    "    + In linear-algebra-terms, it means that if you project the variables on the residuals, the relationship is *orthogonal*.\n",
    "    + Remember that, by the cosine law: the angle between two vectors is $cos(\\theta) = \\dfrac{\\bf{a}'\\bf{b}}{\\big|\\bf{a}\\big| \\ \\big|\\bf{b}\\big|}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "- Or:\n",
    "\n",
    "![img](../img/regasproj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "Let $f(\\bf{X}) = \\bf{X}'$ and that the conditional expectation of $y$ given $X$ is linear (i.e., $\\mathbb{E}(\\bf{y}|\\bf{X}) = \\bf{X}\\bf{\\beta} $). Then:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\bf{0} & = \\mathbb{E}(f(\\bf{X})\\bf{\\varepsilon}) \\\\\n",
    "        & = \\mathbb{E}(\\bf{X}'\\bf{\\varepsilon}) \\\\\n",
    "        & = \\mathbb{E}(\\bf{X}'(\\bf{y} - \\mathbb{E}(\\bf{y}|\\bf{X}))) \\\\\n",
    "        & = \\mathbb{E}(\\bf{X}'(\\bf{y} - \\bf{X}\\bf{\\beta})) \\\\\n",
    "        & = \\mathbb{E}(\\bf{X}'\\bf{y}) - \\mathbb{E}(\\bf{X}'\\bf{X}\\bf{\\beta})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Thus: \n",
    "\n",
    "$$ \\bf{\\beta} \\ = \\ \\mathbb{E}\\big(\\bf{X}'\\bf{X}\\big)^{-1}\\mathbb{E}\\big(\\bf{X}'\\bf{y}\\big) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "- Let us now look at each individual value. \n",
    "\n",
    "**Theorem**: Assuming that for each $i$:\n",
    "\n",
    "$$ Y_i \\ = \\ \\mathbb{E}(Y_i|X_i) + \\varepsilon_i $$\n",
    "\n",
    "Then, $\\mathbb{E}\\big[\\varepsilon_i|X_i\\big] = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "What is the `minimum mean squared error predictor` (MHE, Chapter 3)?\n",
    "\n",
    "**Theorem**: Suppose that there exists a function $m(X_i)$ that minimizes:\n",
    "\n",
    "$$ S(m(X_i)) \\ = \\ \\mathbb{E}\\bigg[\\big(Y_i - m(X_i)\\big)^2\\bigg] $$\n",
    "\n",
    "Then, $m(X_i) = \\mathbb{E}\\big(Y_i|X_i\\big)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "- Since we operate in a sample, can we recover the *population* parameters using the *sample* parameters?\n",
    "\n",
    "**Theorem**: Let $\\bf{\\beta} \\ = \\ \\mathbb{E}\\big[\\bf{X}'\\bf{X}\\big]^{-1}\\mathbb{E}\\big[\\bf{X}'\\bf{y}\\big] $ and let the MSE estimator in the sample $\\widehat{\\bf{\\beta}} \\ = \\ \\big[\\bf{X}'\\bf{X}\\big]^{-1}\\bf{X}'\\bf{y} $. Then:\n",
    "\n",
    "$$ \\mathbb{E}\\big[\\widehat{\\bf{\\beta}} | \\bf{X}\\big] \\ = \\ \\bf{\\beta} + \\mathbb{E}\\bigg[ \\big[\\bf{X}'\\bf{X}\\big]^{-1}\\bf{X}'\\bf{\\varepsilon} \\ | \\ \\bf{X}\\bigg] \\ = \\ \\bf{\\beta}$$\n",
    "\n",
    "But how does that help us to find the ATE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "Let the ATE: \n",
    "\n",
    "$$ \\tau \\ = \\ \\mathbb{E}\\big[Y_{1i} - Y_{0i}\\big] $$\n",
    "\n",
    "And assume all assumptions hold: positivity + CIA. This means that $(Y_1, Y_0) \\perp Z$ (and remember that $Y_{1i} = (Y_i | Z_i = 1)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "And let us consider that $Y_i$ is equal to:\n",
    "\n",
    "$$ Y_i \\ = \\ Z_i \\beta + \\varepsilon_i $$\n",
    "\n",
    "It is easy to see that:\n",
    "\n",
    "$$ \\mathbb{E} \\big[Y_i | Z_i \\big] \\ = \\ \\mathbb{E} \\big[Z_i | Z_i\\big] \\beta + \\mathbb{E} \\big[\\varepsilon_i  | Z_i \\big] $$\n",
    "\n",
    "And since these are exogenous: $\\mathbb{E} \\big[\\varepsilon_i  | Z_i \\big] = 0$, what makes:\n",
    "\n",
    "$$ \\beta \\ = \\ \\mathbb{E} \\big[Y_i | Z_i \\big] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "This is still not that helpful, but remember that $Y_i = Z_iY_{1i} + (1 - Z_i)Y_{0i}$. A little algebra gets:\n",
    "\n",
    "$$ Y_i = Y_{0i} + (Y_{1i} - Y_{0i})Z_i $$\n",
    "\n",
    "And plugging this in:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\beta & = \\mathbb{E} \\big[Y_{0i} + (Y_{1i} - Y_{0i})Z_i | Z_i \\big]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And now what? Complete the proof to find that: $\\beta = \\tau$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression for Causal Identification\n",
    "\n",
    "### The linear regression coefficient is equivalent to the differences-in-means estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## See you in the next class!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
